{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки numpy и pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pandas import Series, DataFrame\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from category_encoders import WOEEncoder,SumEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from numpy.random import RandomState\n",
    "#Загружаем данные\n",
    "data = pd.read_excel('credit_train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заменяем пропущенные значения в age, score_shk, monthly_income и credit_sum \n",
    "data['age'] = np.where(data['age'].isnull(), data['age'].median(), data['age'])\n",
    "data['score_shk'] = np.where(data['score_shk'].isnull(), data['score_shk'].median(), data['score_shk'])\n",
    "data['credit_sum'] = np.where(data['credit_sum'].isnull(), data['credit_sum'].median(), data['credit_sum'])\n",
    "data['monthly_income'] = np.where(data['monthly_income'].isnull(), data['monthly_income'].median(), data['monthly_income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('client_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>job_position</th>\n",
       "      <th>credit_sum</th>\n",
       "      <th>credit_month</th>\n",
       "      <th>tariff_id</th>\n",
       "      <th>score_shk</th>\n",
       "      <th>education</th>\n",
       "      <th>living_region</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>credit_count</th>\n",
       "      <th>overdue_credit_count</th>\n",
       "      <th>open_account_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UMN</td>\n",
       "      <td>59998.00</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-06-01 00:00:00</td>\n",
       "      <td>0.461599</td>\n",
       "      <td>GRD</td>\n",
       "      <td>КРАСНОДАРСКИЙ КРАЙ</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>MAR</td>\n",
       "      <td>UMN</td>\n",
       "      <td>10889.00</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.461599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>МОСКВА</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>32.0</td>\n",
       "      <td>MAR</td>\n",
       "      <td>SPC</td>\n",
       "      <td>10728.00</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.461599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ОБЛ САРАТОВСКАЯ</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPC</td>\n",
       "      <td>12009.09</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.461599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ОБЛ ВОЛГОГРАДСКАЯ</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPC</td>\n",
       "      <td>21229.00</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.421385</td>\n",
       "      <td>SCH</td>\n",
       "      <td>ЧЕЛЯБИНСКАЯ ОБЛАСТЬ</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   age marital_status job_position  credit_sum  credit_month  \\\n",
       "0      M  34.0            NaN          UMN    59998.00            10   \n",
       "1      F  34.0            MAR          UMN    10889.00             6   \n",
       "2      M  32.0            MAR          SPC    10728.00            12   \n",
       "3      F  27.0            NaN          SPC    12009.09            12   \n",
       "4      M  45.0            NaN          SPC    21229.00            10   \n",
       "\n",
       "             tariff_id  score_shk education        living_region  \\\n",
       "0  2019-06-01 00:00:00   0.461599       GRD   КРАСНОДАРСКИЙ КРАЙ   \n",
       "1  2019-01-01 00:00:00   0.461599       NaN               МОСКВА   \n",
       "2  2019-01-01 00:00:00   0.461599       NaN      ОБЛ САРАТОВСКАЯ   \n",
       "3  2019-01-01 00:00:00   0.461599       NaN    ОБЛ ВОЛГОГРАДСКАЯ   \n",
       "4  2019-01-01 00:00:00   0.421385       SCH  ЧЕЛЯБИНСКАЯ ОБЛАСТЬ   \n",
       "\n",
       "   monthly_income  credit_count  overdue_credit_count  open_account_flg  \n",
       "0         30000.0           1.0                   1.0                 0  \n",
       "1         35000.0           2.0                   0.0                 0  \n",
       "2         35000.0           5.0                   0.0                 0  \n",
       "3         35000.0           2.0                   0.0                 0  \n",
       "4         35000.0           1.0                   0.0                 0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'КРАЙ КРАСНОДАРСКИЙ')\n",
    "                                 |(data['living_region'] == 'КРАСНОДАРСКИЙ'), 'КРАСНОДАРСКИЙ КРАЙ', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'МОСКВА Г')\n",
    "                                 |(data['living_region'] == 'Г МОСКВА')\n",
    "                                 |(data['living_region'] == 'Г.МОСКВА')\n",
    "                                 |(data['living_region'] == 'Г. МОСКВА'), 'МОСКВА', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'ОБЛ.МОСКОВСКАЯ')\n",
    "                                 |(data['living_region'] == 'МОСКОВСКАЯ ОБЛ')\n",
    "                                 |(data['living_region'] == 'МОСКОВСКАЯ')\n",
    "                                 |(data['living_region'] == 'МОСКВОСКАЯ ОБЛ')\n",
    "                                 |(data['living_region'] == 'МОСКОВСКАЯ ОБЛАСТЬ'), 'ОБЛ МОСКОВСКАЯ', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'САНКТ-ПЕТЕРБУРГ Г')\n",
    "                                 |(data['living_region'] == 'Г. САНКТ-ПЕТЕРБУРГ'), 'САНКТ-ПЕТЕРБУРГ', data['living_region'])\n",
    "\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'РЕСП ТАТАРСТАН')\n",
    "                                 |(data['living_region'] == 'РЕСПУБЛИКАТАТАРСТАН')\n",
    "                                 |(data['living_region'] == 'РЕСПУБЛИКА ТАТАРСТАН'), 'ТАТАРСТАН РЕСП', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'РЕСП.БАШКОРТОСТАН')\n",
    "                                 |(data['living_region'] == 'РЕСП. БАШКОРТОСТАН')\n",
    "                                 |(data['living_region'] == 'БАШКОРТОСТАН')\n",
    "                                 |(data['living_region'] == 'БАШКОРТОСТАН РЕСП'), 'РЕСП БАШКОРТОСТАН', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'ИРКУТСКАЯ ОБЛ')\n",
    "                                 |(data['living_region'] == 'ИРКУТСКАЯ ОБЛАСТЬ'), 'ОБЛ ИРКУТСКАЯ', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'ОБЛ СВЕРДЛОВСКАЯ')\n",
    "                                 |(data['living_region'] == 'ОБЛ. СВЕРДЛОВСКАЯ')\n",
    "                                 |(data['living_region'] == 'СВЕРДЛОВСКАЯ')\n",
    "                                 |(data['living_region'] == 'СВЕРДЛОВСКАЯ ОБЛАСТЬ'), 'СВЕРДЛОВСКАЯ ОБЛ', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'ОБЛ.НИЖЕГОРОДСКАЯ')\n",
    "                                 |(data['living_region'] == 'НИЖЕГОРОДСКАЯ ОБЛ'), 'ОБЛ НИЖЕГОРОДСКАЯ', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'САХА /ЯКУТИЯ/')\n",
    "                                 |(data['living_region'] == 'САХА (ЯКУТИЯ)'), 'САХА', data['living_region'])\n",
    "\n",
    "data['living_region'] = np.where((data['living_region'] == 'ЧУВАШСКАЯ  - ЧУВАШИЯ')\n",
    "                                 |(data['living_region'] == 'ЧУВАШСКАЯ - ЧУВАШИЯ')\n",
    "                                 |(data['living_region'] == 'ЧУВАШИЯ ЧУВАШСКАЯ  -')\n",
    "                                 |(data['living_region'] == 'ЧУВАШСКАЯ'), 'ЧУВАШИЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = data['living_region'].str.replace('КРАЙ', '')\n",
    "data['living_region'] = data['living_region'].str.replace('РЕСПУБЛИКА', '')\n",
    "data['living_region'] = data['living_region'].str.replace('РЕСП.', '')\n",
    "data['living_region'] = data['living_region'].str.replace('РЕСП', '')\n",
    "data['living_region'] = data['living_region'].str.replace('ОБЛАСТЬ', '')\n",
    "data['living_region'] = data['living_region'].str.replace(' ОБЛАСТЬ', '')\n",
    "data['living_region'] = data['living_region'].str.replace('ОБЛ ', '')\n",
    "data['living_region'] = data['living_region'].str.replace(' ОБЛ', '')\n",
    "data['living_region'] = data['living_region'].str.replace('ОБЛ. ', '')\n",
    "data['living_region'] = data['living_region'].str.replace('.', '')\n",
    "data['living_region'] = data['living_region'].str.strip(' ')\n",
    "data['living_region'] = data['living_region'].str.replace(' АО', '')\n",
    "data['living_region'] = data['living_region'].str.replace('АО ', '')\n",
    "data['living_region'] = data['living_region'].str.replace('АО', '')\n",
    "data['living_region'] = data['living_region'].str.strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'].isnull())|(data['living_region'] == 'РОССИЯ')|(data['living_region'] == 'ПРИВОЛЖСКИЙ ФЕДЕРАЛЬНЫЙ ОКРУГ'), 'Центральный', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tariff_id'] = np.where(data['tariff_id'] == '1.0', '2019-01-01 00:00:00', data['tariff_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region_area'] = data['living_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region_area'] = np.where((data['living_region_area'] == 'ЧУВАШСКАЯ  - ЧУВАШИЯ')\n",
    "                                 |(data['living_region_area'] == 'ЧУВАШСКАЯ - ЧУВАШИЯ')\n",
    "                                 |(data['living_region_area'] == 'ЧУВАШИЯ ЧУВАШСКАЯ  -')\n",
    "                                 |(data['living_region_area'] == 'ЧУВАШСКАЯ'), 'ЧУВАШИЯ', data['living_region_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region_area'] = np.where((data['living_region_area'] == 'САХА /ЯКУТИЯ/')\n",
    "                                 |(data['living_region_area'] == 'САХА (ЯКУТИЯ)'), 'САХА', data['living_region_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicta = {98: 'Other'}\n",
    "data['living_region'].replace(dicta, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicta_dicta = {'БРЯНСКАЯ': 'Центральный', 'ВЛАДИМИРСКАЯ' : 'Центральный', 'ИВАНОВСКАЯ': 'Центральный', 'КАЛУЖСКАЯ' : 'Центральный', 'КОСТРОМСКАЯ' : 'Центральный', 'МОСКОВСКАЯ' : 'Центральный', \n",
    "              'ОРЛОВСКАЯ': 'Центральный', 'РЯЗАНСКАЯ': 'Центральный', 'СМОЛЕНСКАЯ': 'Центральный', 'ТВЕРСКАЯ': 'Центральный', 'ТУЛЬСКАЯ': 'Центральный', 'ЯРОСЛАВСКАЯ': 'Центральный', 'МОСКВА': 'Центральный',\n",
    "              'БЕЛГОРОДСКАЯ': 'Центрально-Чернозёмный', 'ВОРОНЕЖСКАЯ': 'Центрально-Чернозёмный', 'КУРСКАЯ': 'Центрально-Чернозёмный', 'ЛИПЕЦКАЯ': 'Центрально-Чернозёмный', 'ТАМБОВСКАЯ': 'Центрально-Чернозёмный',\n",
    "              'КРАСНОДАРСКИЙ' : 'Северо-Кавказский', 'САРАТОВСКАЯ' : 'Поволжский', 'ВОЛГОГРАДСКАЯ' : 'Поволжский', 'ЧЕЛЯБИНСКАЯ': 'Уральский', 'СТАВРОПОЛЬСКИЙ': 'Поволжский', 'НИЖЕГОРОДСКАЯ': 'Волго-Вятский',\n",
    "               'ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУГ - ЮГРА' : 'Западно-Сибирский', 'САНКТ-ПЕТЕРБУРГ' : 'Северо-Западный', 'БАШКОРТОСТАН': 'Поволжский', 'АРХАНГЕЛЬСКАЯ': 'Северный', 'ХАНТЫ-МАНСИЙСКИЙ': 'Западно-Сибирский', \n",
    "               'ПЕРМСКИЙ': 'Уральский', 'КАРАЧАЕВО-ЧЕРКЕССКАЯ': 'Северо-Кавказский', 'ВОЛОГОДСКАЯ' : 'Северный', 'РОСТОВСКАЯ' : 'Северо-Кавказский', 'УДМУРТСКАЯ': 'Уральский', 'ИРКУТСКАЯ': 'Восточно-Сибирский', 'ТЮМЕНСКАЯ': 'Западно-Сибирский',\n",
    "               'ХАКАСИЯ': 'Восточно-Сибирский', 'ТАТАРСТАН' : 'Поволжский', 'СВЕРДЛОВСКАЯ': 'Уральский', 'ПСКОВСКАЯ': 'Северо-Западный', 'ЗАБАЙКАЛЬСКИЙ': 'Восточно-Сибирский', 'ОРЕНБУРГСКАЯ' : 'Уральский', 'АСТРАХАНСКАЯ': 'Поволжский', 'НОВОСИБИРСКАЯ' : 'Западно-Сибирский',\n",
    "               'КУРГАНСКАЯ': 'Уральский', 'УЛЬЯНОВСКАЯ' : 'Поволжский', 'МУРМАНСКАЯ' : 'Северный', 'КРАСНОЯРСКИЙ' : 'Восточно-Сибирский', 'БУРЯТИЯ' : 'Восточно-Сибирский', 'САХА': 'Дальневосточный', 'АМУРСКАЯ': 'Дальневосточный', 'ХАБАРОВСКИЙ' : 'Дальневосточный', 'ЯМАЛО-НЕНЕЦКИЙ': 'Западно-Сибирский',\n",
    "               'САМАРСКАЯ': 'Поволжский', 'ЛЕНИНГРАДСКАЯ': 'Северо-Западный', 'КЕМЕРОВСКАЯ' : 'Западно-Сибирский', 'ОМСКАЯ': 'Западно-Сибирский', 'ЧЕЧЕНСКАЯ' : 'Северо-Кавказский', 'АДЫГЕЯ': 'Северо-Кавказский', 'КОМИ': 'Северный', 'ПРИМОРСКИЙ' : 'Дальневосточный', 'КИРОВСКАЯ': 'Волго-Вятский', 'ДАГЕСТАН': 'Северо-Кавказский',\n",
    "               'ПЕНЗЕНСКАЯ': 'Поволжский', 'КАРЕЛИЯ': 'Северный', 'ТОМСКАЯ': 'Западно-Сибирский', 'МАГАДАНСКАЯ': 'Дальневосточный', 'МАРИЙ ЭЛ': 'Волго-Вятский', 'ЕВРЕЙСКАЯБЛ': 'Дальневосточный', 'АЛТАЙСКИЙ':'Западно-Сибирский', 'КАБАРДИНО-БАЛКАРСКАЯ':'Северо-Кавказский', 'ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУГ - Ю':'Западно-Сибирский', 'ТЫВА':'Восточно-Сибирский',\n",
    "               'НОВГОРОДСКАЯ': 'Северо-Западный', 'СЕВЕРНАЯ ОСЕТИЯ - АЛАНИЯ': 'Северо-Кавказский', 'САХАЛИНСКАЯ': 'Дальневосточный', 'ЧУВАШИЯ':'Волго-Вятский', 'КАМЧАТСКИЙ': 'Дальневосточный', 'МОРДОВИЯ': 'Волго-Вятский', 'КАЛМЫКИЯ': 'Поволжский', 'АЛТАЙ': 'Западно-Сибирский', 'КАЛИНИНГРАДСКАЯ':'Центральный', 'НЕНЕЦКИЙ':'Западно-Сибирский', 'ПЕРМСКАЯ':'Уральский', 'ЧУКОТСКИЙ': 'Дальневосточный',\n",
    "               'ГОРЬКОВСКАЯ': 'Волго-Вятский', 'СЕВ ОСЕТИЯ - АЛАНИЯ': 'Северо-Кавказский', 'ИНГУШЕТИЯ': 'Северо-Кавказский', 'ЧИТИНСКАЯ': 'Западно-Сибирский', 'МЫТИЩИНСКИЙ Р-Н': 'Центральный', 'ОБЛРОСТОВСКАЯ' : 'Северо-Кавказский', 'ЕВРЕЙСКАЯ АВТОНОМНАЯ': 'Дальневосточный', 'ЭВЕНКИЙСКИЙ':'Восточно-Сибирский', 'КАМЧАТСКАЯ': 'Дальневосточный', 'ГУСЬ-ХРУСТАЛЬНЫЙ Р-Н': 'Центральный', 'БРЯНСКИЙ': 'Центральный',\n",
    "               'ОРЁЛ': 'Центральный', 'АЕВРЕЙСКАЯ': 'Дальневосточный', 'ОБЛСАРАТОВСКАЯ': 'Поволжский', 'ДАЛЬНИЙ ВОСТОК' : 'Дальневосточный', 'ГОДИНЦОВО МОСКОВСКАЯ': 'Центральный'\n",
    "              }\n",
    "\n",
    "data['living_region_area'].replace(dicta_dicta, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'САХА /ЯКУТИЯ/')|\n",
    "                                 (data['living_region'] == 'САХА (ЯКУТИЯ)'), 'САХА', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ЧУВАШСКАЯ  - ЧУВАШИЯ')\n",
    "                                 |(data['living_region'] == 'ЧУВАШСКАЯ - ЧУВАШИЯ')\n",
    "                                 |(data['living_region'] == 'ЧУВАШИЯ ЧУВАШСКАЯ  -')\n",
    "                                 |(data['living_region'] == 'ЧУВАШСКАЯ'), 'ЧУВАШИЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУГ - ЮГРА')|\n",
    "                                 (data['living_region'] == 'ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУГ - Ю')|\n",
    "                                 (data['living_region'] == 'ХАНТЫ-МАНСИЙСКИЙ'), 'ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУГ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ЕВРЕЙСКАЯБЛ')|\n",
    "                                 (data['living_region'] == 'ЕВРЕЙСКАЯ АВТОНОМНАЯ')|\n",
    "                                 (data['living_region'] == 'ЕВРЕЙСКАЯ АВТОНОМНАЯ'), 'ЕВРЕЙСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'АЛТАЙСКИЙ'), 'АЛТАЙ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'БРЯНСКАЯ'), 'БРЯНСКИЙ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ГОДИНЦОВО МОСКОВСКАЯ'), 'МОСКОВСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ГУСЬ-ХРУСТАЛЬНЫЙ Р-Н'), 'ВЛАДИМИРСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ГОРЬКОВСКАЯ'), 'НИЖЕГОРОДСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'КАМЧАТСКИЙ'), 'КАМЧАТСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'МЫТИЩИНСКИЙ Р-Н'), 'МОСКОВСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ОБЛРОСТОВСКАЯ'), 'РОСТОВСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'ОБЛСАРАТОВСКАЯ'), 'САРАТОВСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'СЕВ ОСЕТИЯ - АЛАНИЯ'), 'СЕВЕРНАЯ ОСЕТИЯ - АЛАНИЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'НЕНЕЦКИЙ'), 'ЯМАЛО-НЕНЕЦКИЙ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['living_region'] = np.where((data['living_region'] == 'САХА'), 'САХАЛИНСКАЯ', data['living_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Первый созданный нами признак - Payment - сумма кредита / срок кредита\n",
    "data['payment'] = data['credit_sum'] / data['credit_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Второй признак - share_income - доля дохода от суммы кредита\n",
    "data['share_income'] = data['monthly_income'] / data['credit_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Третий признак - income_to_credit - отношение месячной зарплаты к временному периоду погашения кредита\n",
    "data['income_to_credit'] = data['age'] / data['credit_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['retired'] = np.where(data['age']>=60, 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_retired'] = np.where((data['age'] > 35) & (data['credit_sum'] > 10000), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_retired'] = np.where((data['age'] > 35) & (data['credit_sum'] > 10000), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rich_and_married'] = np.where((data['marital_status'] == 'MAR') & (data['monthly_income'] > 50000), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rich_and_DIR'] = np.where((data['job_position'] == 'DIR') & (data['monthly_income'] > data['monthly_income'].median()), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rich_and_INP'] = np.where((data['job_position'] == 'INP') & (data['monthly_income'] > data['monthly_income'].median()), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rich_and_BIS'] = np.where((data['job_position'] == 'BIS') & (data['monthly_income'] > data['monthly_income'].median()), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['north_and_education_is_ACD'] = np.where((data['education'] == 'ACD') \n",
    "                                              & (data['living_region_area'] == 'Северный'), 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicta_dict = {'UMN': 51000, 'SPC': 63000, 'INP': 55000, 'DIR': 60000,\n",
    "'ATP': 46000, 'PNA': 71000, 'BIS': 86000, 'WOI': 76000,\n",
    "'NOR': 54000, 'WRK': 77000, 'WRP': 75000, 'PNV': 67000,\n",
    "'BIU': 43000, 'PNI': 69000, 'HSK': 74000, 'PNS': 44000,\n",
    "'INV': 88000, 'ONB': 62000, 'OTHER': 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['average_zp'] = data['job_position'].map(dicta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['credit_pressure'] = data['monthly_income'] / data['payment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         34.0\n",
      "1         34.0\n",
      "2         32.0\n",
      "3         27.0\n",
      "4         45.0\n",
      "          ... \n",
      "170741    27.0\n",
      "170742    24.0\n",
      "170743    31.0\n",
      "170744    53.0\n",
      "170745    49.0\n",
      "Name: age, Length: 170746, dtype: float64 111.21720213530762\n",
      "0         59998.00\n",
      "1         10889.00\n",
      "2         10728.00\n",
      "3         12009.09\n",
      "4         21229.00\n",
      "            ...   \n",
      "170741    64867.00\n",
      "170742    17640.00\n",
      "170743    27556.47\n",
      "170744     6189.00\n",
      "170745    12787.00\n",
      "Name: credit_sum, Length: 170746, dtype: float64 263568326.92380592\n",
      "0         10\n",
      "1          6\n",
      "2         12\n",
      "3         12\n",
      "4         10\n",
      "          ..\n",
      "170741    12\n",
      "170742     6\n",
      "170743    10\n",
      "170744    12\n",
      "170745    10\n",
      "Name: credit_month, Length: 170746, dtype: int64 12.508229948550715\n",
      "0         0.461599\n",
      "1         0.461599\n",
      "2         0.461599\n",
      "3         0.461599\n",
      "4         0.421385\n",
      "            ...   \n",
      "170741    0.535257\n",
      "170742    0.573287\n",
      "170743    0.416098\n",
      "170744    0.482595\n",
      "170745    0.316087\n",
      "Name: score_shk, Length: 170746, dtype: float64 0.015441249395329606\n",
      "0         30000.0\n",
      "1         35000.0\n",
      "2         35000.0\n",
      "3         35000.0\n",
      "4         35000.0\n",
      "           ...   \n",
      "170741    40000.0\n",
      "170742    30000.0\n",
      "170743    40000.0\n",
      "170744    31000.0\n",
      "170745    40000.0\n",
      "Name: monthly_income, Length: 170746, dtype: float64 627203074.7075973\n",
      "0         1.0\n",
      "1         2.0\n",
      "2         5.0\n",
      "3         2.0\n",
      "4         1.0\n",
      "         ... \n",
      "170741    6.0\n",
      "170742    1.0\n",
      "170743    1.0\n",
      "170744    2.0\n",
      "170745    3.0\n",
      "Name: credit_count, Length: 170746, dtype: float64 3.1581842759860725\n",
      "0         1.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "170741    0.0\n",
      "170742    0.0\n",
      "170743    0.0\n",
      "170744    0.0\n",
      "170745    0.0\n",
      "Name: overdue_credit_count, Length: 170746, dtype: float64 0.044752469247272525\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "170741    0\n",
      "170742    0\n",
      "170743    0\n",
      "170744    0\n",
      "170745    0\n",
      "Name: open_account_flg, Length: 170746, dtype: int64 0.14504270090683408\n",
      "0         5999.800000\n",
      "1         1814.833333\n",
      "2          894.000000\n",
      "3         1000.757500\n",
      "4         2122.900000\n",
      "             ...     \n",
      "170741    5405.583333\n",
      "170742    2940.000000\n",
      "170743    2755.647000\n",
      "170744     515.750000\n",
      "170745    1278.700000\n",
      "Name: payment, Length: 170746, dtype: float64 2446253.094014227\n",
      "0         0.500017\n",
      "1         3.214253\n",
      "2         3.262491\n",
      "3         2.914459\n",
      "4         1.648688\n",
      "            ...   \n",
      "170741    0.616646\n",
      "170742    1.700680\n",
      "170743    1.451565\n",
      "170744    5.008887\n",
      "170745    3.128177\n",
      "Name: share_income, Length: 170746, dtype: float64 2.575517752231529\n",
      "0         3.400000\n",
      "1         5.666667\n",
      "2         2.666667\n",
      "3         2.250000\n",
      "4         4.500000\n",
      "            ...   \n",
      "170741    2.250000\n",
      "170742    4.000000\n",
      "170743    3.100000\n",
      "170744    4.416667\n",
      "170745    4.900000\n",
      "Name: income_to_credit, Length: 170746, dtype: float64 2.7476134681137547\n",
      "0         51000\n",
      "1         51000\n",
      "2         63000\n",
      "3         63000\n",
      "4         63000\n",
      "          ...  \n",
      "170741    63000\n",
      "170742    63000\n",
      "170743    63000\n",
      "170744    71000\n",
      "170745    63000\n",
      "Name: average_zp, Length: 170746, dtype: int64 40225987.018185236\n",
      "0          5.000167\n",
      "1         19.285517\n",
      "2         39.149888\n",
      "3         34.973508\n",
      "4         16.486881\n",
      "            ...    \n",
      "170741     7.399756\n",
      "170742    10.204082\n",
      "170743    14.515647\n",
      "170744    60.106641\n",
      "170745    31.281771\n",
      "Name: credit_pressure, Length: 170746, dtype: float64 261.030430750608\n"
     ]
    }
   ],
   "source": [
    "for i in data.select_dtypes(include='number').columns:\n",
    "    print(data[i], data[i].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    170746.000000\n",
       "mean      26095.040543\n",
       "std       16234.787554\n",
       "min        2736.000000\n",
       "25%       14908.000000\n",
       "50%       21229.000000\n",
       "75%       32068.000000\n",
       "max      200000.000000\n",
       "Name: credit_sum, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['credit_sum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "listok = ['credit_sum', 'monthly_income', 'payment', 'average_zp', 'age', 'share_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем обучающий массив признаков, обучающий массив меток,\n",
    "# тестовый массив признаков, тестовый массив меток\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('open_account_flg', axis=1), \n",
    "                                                data['open_account_flg'], \n",
    "                                                test_size=.3, \n",
    "                                                stratify=data['open_account_flg'], \n",
    "                                                random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем функцию для проверки признаков по AUC\n",
    "def importace_auc(train, test):\n",
    "    train_copy = train.copy()\n",
    "    test_copy = test.copy()\n",
    "    #Выбираем нужные нам признаки с числовым типом данных\n",
    "    col_list = train.select_dtypes(include = ['number']).columns\n",
    "    #Создаем словарь\n",
    "    auc_list = []\n",
    "    for i in col_list:\n",
    "        #Заменяем все пропущенные значения на медианное\n",
    "        train_copy[i].fillna(train_copy[i].median(), inplace = True)\n",
    "        # Создаем экземляр класса PowerTransformer\n",
    "        power = PowerTransformer(method = 'yeo-johnson', standardize = True).fit(train_copy[[i]])\n",
    "        #Трансформируем данные тренировочной выборки\n",
    "        train_copy[i] = power.transform(train_copy[[i]])\n",
    "        #Заменяем все пропущенные значения на медианное\n",
    "        test_copy[i].fillna(test_copy[i].median(), inplace = True)\n",
    "        #Трансформируем данные тестовой выборки\n",
    "        test_copy[i] = power.transform(test_copy[[i]])\n",
    "        #Создаем экземпляр класса LogisticRegression\n",
    "        logreg = LogisticRegression(solver = 'liblinear').fit(train_copy[[i]], y_train)\n",
    "        #Подсчитываем значение AUC для каждой категории\n",
    "        auc = roc_auc_score(y_test, logreg.predict_proba(test_copy[[i]])[:, 1])\n",
    "        #Добавляет в наш пустой список значения auc\n",
    "        auc_list.append(auc)\n",
    "    #Создаем датафрейм с показателями auc\n",
    "    result = pd.DataFrame({'Переменная': col_list, 'AUC': auc_list})\n",
    "    #Округляем значения и сортируем по убыванию\n",
    "    result = np.round(result.sort_values(by = 'AUC', ascending = False), 3)\n",
    "    #Форматирование по цвету\n",
    "    cm = sns.light_palette('yellow', as_cmap = True)\n",
    "    return(result.style.background_gradient(cmap = cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['tariff_id'] = X_train['tariff_id'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем собственный класс Replacer, заменяющие отрицательные\n",
    "# и нулевые значения на небольшие положительные (необходимо\n",
    "# перед применением логарифмического и обратного преобразований)\n",
    "class Replacer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "        repl: значение для замены\n",
    "    \"\"\"\n",
    "    def __init__(self, repl_value=0.1):\n",
    "        self.repl_value = repl_value\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_replaced = np.where(X <= 0, self.repl_value, X)\n",
    "        return X_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = X_train.select_dtypes('object').columns\n",
    "num_columns = X_train.select_dtypes(include = ['int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_columns = list(set(num_columns).difference(set(listok)))\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'marital_status', 'job_position', 'tariff_id', 'education',\n",
       "       'living_region', 'living_region_area', 'retired', 'age_retired',\n",
       "       'rich_and_married', 'rich_and_DIR', 'rich_and_INP', 'rich_and_BIS',\n",
       "       'north_and_education_is_ACD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Трансформер для категориальных переменных\n",
    "cat_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "    ('derp', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Трансформер для количественных переменных\n",
    "num_pipe = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='mean')),\n",
    "    ('repl', Replacer(repl_value=0.1)),\n",
    "    ('yeo', PowerTransformer(method = 'box-cox', standardize = True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Трансформер для количественных переменных\n",
    "num_pipe_test = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='mean')),\n",
    "    ('repl', Replacer(repl_value=0.1)),\n",
    "    ('yeo', PowerTransformer(method = 'box-cox', standardize = True)),\n",
    "    ('bi', KBinsDiscretizer(encode='onehot-dense'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Конвеер\n",
    "transformers = [('cat', cat_pipe, cat_columns),\n",
    "               ('num_bin', num_pipe_test, num_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Финальный трансформер\n",
    "pipe = Pipeline([('tf', transformer), \n",
    "                 ('logreg', LogisticRegression(solver='liblinear', random_state=42, C=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры для модели\n",
    "param_grid = [\n",
    "    {'logreg__C': [8],\n",
    "    'tf__num_bin__bi__n_bins': [10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка экземпляра класса перекрестной проверки\n",
    "strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модель GridSearchCV\n",
    "gs = GridSearchCV(pipe, param_grid, scoring='roc_auc',cv=strat, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "C:\\Users\\NARYB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:193: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tf',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imp',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_val...\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=42,\n",
       "                                                           solver='liblinear',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'logreg__C': [8], 'tf__num_bin__bi__n_bins': [10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров: {'logreg__C': 8, 'tf__num_bin__bi__n_bins': 10}\n",
      "Наилучшее значение правильности: 0.751\n",
      "Значение правильности на тестовой выборке: 0.753\n"
     ]
    }
   ],
   "source": [
    "# Наилучшие значения гиперпараметров\n",
    "print('Наилучшие значения гиперпараметров: {}'.format(gs.best_params_))\n",
    "# Наилучшее значение правильности\n",
    "print('Наилучшее значение правильности: {:.3f}'.format(gs.best_score_))\n",
    "# Значение правильности\n",
    "print('Значение правильности на тестовой выборке: {:.3f}'.format(gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
